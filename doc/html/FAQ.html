<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>FAQ &mdash; S3QL v0.8 documentation</title>
    <link rel="stylesheet" href="_static/sphinxdoc.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '',
        VERSION:     '0.8',
        COLLAPSE_MODINDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <link rel="author" title="About these documents" href="about.html" />
    <link rel="top" title="S3QL v0.8 documentation" href="index.html" />
    <link rel="prev" title="Installation" href="Installation.html" /> 
  </head>
  <body>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="Installation.html" title="Installation"
             accesskey="P">previous</a></li>
        <li><a href="index.html">S3QL v0.8 documentation</a> &raquo;</li> 
      </ul>
    </div>
      <div class="sphinxsidebar">
        <div class="sphinxsidebarwrapper">
            <h3><a href="index.html">Table Of Contents</a></h3>
            <ul class="current">
<li class="toctree-l1"><a class="reference external" href="about.html">About S3QL</a></li>
<li class="toctree-l1"><a class="reference external" href="Installation.html">Installation</a></li>
<li class="toctree-l1 current"><a class="current reference external" href="">FAQ</a><ul>
<li class="toctree-l2"><a class="reference external" href="#mount-fails-with-failed-to-open-dev-fuse">Mount fails with <cite>failed to open /dev/fuse</cite></a></li>
<li class="toctree-l2"><a class="reference external" href="#which-operating-systems-are-supported">Which operating systems are supported?</a></li>
</ul>
</li>
</ul>

	  
          <div id="searchbox" style="display: none">
            <h3>Quick search</h3>
              <form class="search" action="search.html" method="get">
                <input type="text" name="q" size="18" />
                <input type="submit" value="Go" />
                <input type="hidden" name="check_keywords" value="yes" />
                <input type="hidden" name="area" value="default" />
              </form>
              <p class="searchtip" style="font-size: 90%">
              Enter search terms.
              </p>
          </div>
          <script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body">
            
  <div class="section" id="faq">
<h1>FAQ<a class="headerlink" href="#faq" title="Permalink to this headline">¶</a></h1>
<div class="contents local topic" id="contents">
<ul class="simple">
<li><a class="reference internal" href="#mount-fails-with-failed-to-open-dev-fuse" id="id1">Mount fails with <cite>failed to open /dev/fuse</cite></a></li>
<li><a class="reference internal" href="#which-operating-systems-are-supported" id="id2">Which operating systems are supported?</a></li>
</ul>
</div>
<div class="section" id="mount-fails-with-failed-to-open-dev-fuse">
<h2><a class="toc-backref" href="#contents">Mount fails with <cite>failed to open /dev/fuse</cite></a><a class="headerlink" href="#mount-fails-with-failed-to-open-dev-fuse" title="Permalink to this headline">¶</a></h2>
<p>You should make sure that you have the rights to mount FUSE file
systems. In Debian/Ubuntu, you have to add yourself to the <em>fuse</em>
group (e.g. with <tt class="docutils literal"><span class="pre">adduser</span> <span class="pre">&lt;myself&gt;</span> <span class="pre">fuse</span></tt> executed as root).</p>
<p>If you are running under OpenVZ, you also have to explicitly give your
host VM permissions to access the <tt class="docutils literal"><span class="pre">/dev/fuse</span></tt> device (otherwise you
will get the above message even if <tt class="docutils literal"><span class="pre">/dev/fuse</span></tt> is world-writable,
thanks to waltherlalk for the solution).</p>
</div>
<div class="section" id="which-operating-systems-are-supported">
<h2><a class="toc-backref" href="#contents">Which operating systems are supported?</a><a class="headerlink" href="#which-operating-systems-are-supported" title="Permalink to this headline">¶</a></h2>
<p>S3QL is developed on Linux, but should in principle work on all FUSE
supported operating systems that have the required Python modules. The
<cite>umount.s3ql</cite> program does some tricks which may not work on non-Linux
systems, but you can always umount with the <cite>fusermount -u</cite> command
provided by FUSE itself (the only difference is that it will not block
until all data has been uploaded to S3 but return immediately). Please
report your success (or failure) with other operating systems on the
mailing list, so that this information can be extended.</p>
<p>=== Writing data seems to be very slow on my system... ===</p>
<p>Probably you are using a FUSE version that does not support &#8220;big writes&#8221;. Make sure that you have at least FUSE 2.8 and kernel 2.6.26. FUSE 2.8.1 packages for Ubuntu Karmic are available on the [<a class="reference external" href="http://code.google.com/p/s3ql/downloads/list">http://code.google.com/p/s3ql/downloads/list</a> downloads page].</p>
<p>If you already using FUSE 2.8.1, installing [<a class="reference external" href="http://psyco.sourceforge.net/">http://psyco.sourceforge.net/</a> Psyco] (Debian/Ubuntu package <cite>python-psyco</cite>) may give you a little performance boost (S3QL will use Psyco automatically if it is installed).</p>
<p>=== How much do I have to pay Amazon for storage in S3? ===</p>
<p>Amazon&#8217;s current pricing is described on [<a class="reference external" href="http://aws.amazon.com/s3/#pricing">http://aws.amazon.com/s3/#pricing</a> <a class="reference external" href="http://aws.amazon.com/s3/#pricing">http://aws.amazon.com/s3/#pricing</a>]. There is also a [<a class="reference external" href="http://calculator.s3.amazonaws.com/calc5.html">http://calculator.s3.amazonaws.com/calc5.html</a> pricing calculator].</p>
<p>The rough costs that occur when using a bucket to store an S3QL file system are explained on the [S3PricingCompatibility  Interplay with Amazon&#8217;s S3 Pricing] page.</p>
<p>=== Is there a file size limit? ===</p>
<p>No, S3QL puts no limits on the size of your files. The 5 GB limit that Amazon imposes on the limit of individual S3 objects does not matter for S3QL, since files are automatically and transparently split into smaller blocks.</p>
<p>=== Suppose I want to make a small change in a very large file. Will S3QL download and re-upload the entire file? ===</p>
<p>No, S3QL splits files in blocks of a configurable size (default: 10 MB). So to make a small change in a big file, only one block needs to be transferred and not the entire file.</p>
<p>=== I don&#8217;t quite understand this de-duplication feature... ===</p>
<p>The great thing about data de-duplication is that you don&#8217;t need to know anything about it and will still get all the benefits. Towards you, S3QL will behave and look exactly like a file system without data duplication. When talking to the storage backend, however, the S3QL will try to save duplicated data only once and thus take less storage than an ordinary file system would need.</p>
<p>=== What&#8217;s wrong with having S3 buckets in the &#8220;US Standard&#8221; region? ===</p>
<p>The problem with the &#8220;US Standard&#8221; bucket location is that Amazon gives weaker consistency guarantees for data stored in this location. If S3QL has written a new object into a US-Standard bucket, and afterwards _all_ the Amazon servers that have copies of the new object happen to crash, then an attempt to read the object will fail because the object appears not to exist.</p>
<p>S3QL detects and handles this situation keeping track of the objects that it has uploaded, so even the above constellation will generally not lead to problems.</p>
<p>However, the list of uploaded objects itself needs to be stored in S3 as well, and it is therefore theoretically possibly to construct the following race condition:</p>
<blockquote>
# An S3QL file system is mounted, some data is modified
# The file system is unmounted, the new list of active S3 objects is uploaded
# All S3 servers that hold copies of this list crash
# The S3QL file system is mounted again. S3QL downloads the most recent list of active objects
# Since the list that has been uploaded in (2) is not visible (because the servers storing it are still down), S3QL downloads an outdated list and weird file system errors  occur</blockquote>
<p>Obviously this is a <em>very</em> remote chance, since it requires that _all_ the servers holding a copy of one specific object to be down just at the time when you mount the file system (if they go down _while_ the file system is mounted this will not cause any problems). However, it is nevertheless a possibility and therefore S3QL recommends to store buckets in the N. California and EU storage regions, where this problem cannot occur at all. (Once an object has been written into a N. California or EU bucket, Amazon guarantees that it will stay available under all circumstances).</p>
<p>=== What blocksize should I use? ===</p>
<p>A reasonable blocksize is around 1 MB to 50 MB, with 10 MB the default.</p>
<p>If you are going to make lots of small changes to big files, it might be worth to try a lower blocksize to get improved performance (but you should really test this before you go for it).</p>
<p>Generally you should not need to deviate from the default blocksize, unless you know that you have a good reason to do so.</p>
<p>=== I don&#8217;t want to enter my bucket password every time... ===</p>
<p>You can save your password in a file, say <cite>/home/ron/bucket_password</cite> and then pipe the password directly into mount.s3ql, i.e. you execute <cite>cat /home/ron/bucket_password | mount.s3ql &lt;options&gt;</cite>.</p>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="Installation.html" title="Installation"
             >previous</a></li>
        <li><a href="index.html">S3QL v0.8 documentation</a> &raquo;</li> 
      </ul>
    </div>
    <div class="footer">
      &copy; Copyright 2010, Nikolaus Rath.
      Created using <a href="http://sphinx.pocoo.org/">Sphinx</a> 0.6.2.
    </div>
  </body>
</html>